import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns


df = pd.read_csv('dataset.csv')

df.head()

cormat = df.corr()
feature_metrics = cormat.index


plt.figure(figsize=(20,20))

sns.heatmap(cormat, annot= True , cmap = 'RdYlGn')

df.isnull().sum()

df.hist()

sns.set_style('whitegrid')
sns.countplot(x= 'target', data = df)

df.head()

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
col_scale = ['age','trestbps','chol','thalach']
df[col_scale] = sc.fit_transform(df[col_scale])
df.head()

X = df.iloc[:,:-1]
X.head()

y =  df['target']

from sklearn.model_selection import cross_val_score
from sklearn.neighbors import KNeighborsClassifier

knn_scores = []
for i in range(1,21):
    knn_classifier = KNeighborsClassifier(n_neighbors=i)
    cv = cross_val_score(knn_classifier, X, y, cv=10)
    knn_scores.append(cv.mean())

plt.plot([k for k in range(1, 21)], knn_scores, color = 'red')
for i in range(1,21):
    plt.text(i, knn_scores[i-1], (i, knn_scores[i-1]))
plt.xticks([i for i in range(1, 21)])
plt.xlabel('Number of Neighbors (K)')
plt.ylabel('Scores')
plt.title('K Neighbors Classifier scores for different K values')

from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import Lasso
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import ShuffleSplit
def find_best_model_using_gridsearchcv(X,y):
    algos = {
        'RandomForestClassifier' : {
            'model': RandomForestClassifier(),
            'params': {
                                'n_estimators': [10,50,100]
            }
        },
        'KNN': {
            'model': KNeighborsClassifier(),
            'params': {
                'n_neighbors' : [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]
            }
        },
        'decision_tree': {
            'model': DecisionTreeClassifier(),
            'params': {
                 'criterion': ['gini','entropy'],
                'splitter': ['best','random']
            }
        }
    }
    scores = []
    cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)
    for algo_name, config in algos.items():
        gs =  GridSearchCV(config['model'], config['params'],      cv=cv, return_train_score=False)
        gs.fit(X,y)
        scores.append({
            'model': algo_name,
            'best_score': gs.best_score_,
            'best_params': gs.best_params_
        })
    return pd.DataFrame(scores,columns=['model','best_score','best_params'])
outcome = find_best_model_using_gridsearchcv(X,y)
outcome



outcome.model[1]
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X,y)
prediction = knn.predict(X)


import pickle
pickle.dump( outcome.model[1] ,open('hd.pickle','wb'))

model = pickle.load(open('hd.pickle','rb'))
# -*- coding: utf-8 -*-

